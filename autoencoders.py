# -*- coding: utf-8 -*-
"""AutoEncoders.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z32KNoMPqh7kq9lbETAhDODZ4jI9_zwN

# Image compression using auto-encoders with the TensorFlow Keras functional API

We will use 3 models to build the auto-encoders : the encoder, the decoder, and the full auto-encoder. This will make the performance analysis easier.

# Imports :
"""

#install similarity indexes
!pip install image-similarity-measures

#For faster evaluation of the FSIM metric, the pyfftw package is required, install via:
!pip install image-similarity-measures[speedups]
!pip install pyfftw

!pip install tabulate

from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/MyDrive/Image Processing Project/psnr_lib')

import numpy as np
import matplotlib.pyplot as plt
from tabulate import tabulate
import tensorflow as tf

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input, Dense, Lambda, LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.datasets import mnist
from tensorflow.keras.callbacks import ModelCheckpoint, History, ReduceLROnPlateau

from image_similarity_measures import quality_metrics

from psnr_human_vision  import mean_psnr_hvs_m

"""# Definining parameters :

The loss function give the minimum for ```intermediate_dim = 400```
"""

# Model architecture parameters
latent_dim = 32
intermediate_dim = 400

# Model training parameters
nb_epochs = 30
batch_size = 100

"""# Loading the MNIST dataset :"""

# Load MNIST dataset
(x_train, _), (x_test, y_test) = mnist.load_data()

# Normalize pixel values to be between 0 and 1
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Flatten images
input_shape = (28, 28)
original_dim = input_shape[0] * input_shape[1]
x_train = x_train.reshape((len(x_train), original_dim))
x_test = x_test.reshape((len(x_test), original_dim))
print(x_train.shape)
print(x_test.shape)

"""# Building the encoder :"""

encoder_input = Input(shape=original_dim, name="encoder_input")

encoder_intermediate = Dense(intermediate_dim, activation='relu', name="encoder_intermediate")(encoder_input)

encoder_output = Dense(latent_dim, activation='relu', name="encoder_output")(encoder_intermediate)

"""In this example, we use 2 `Dense` layers and 2 `LeakyReLu` activation layers for the encoder. The input data is a 28*28 pixels image which is mapped into a 2 dimensional latent space.

After setting the model up, the next step is to build it using the `Model` function.


"""

encoder = Model(encoder_input, encoder_output, name="encoder")
encoder.summary()

"""The model is not large and the number of units in the `Dense` layer can be increased for better feature detection.

After building the encoder, we will build the decoder.

# Building the decoder :
"""

decoder_input = Input(shape=latent_dim, name="decoder_input")

decoder_intermediate = Dense(intermediate_dim, activation="relu", name="decoder_intermediate")(decoder_input)

decoder_output = Dense(original_dim, activation='sigmoid', name="decoder_output")(decoder_intermediate)

decoder = Model(decoder_input, decoder_output, name="decoder")
decoder.summary()

"""# Building the autoencoder"""

ae_input = Input(shape=original_dim, name="ae_input")
ae_encoder_output = encoder(ae_input)
ae_decoder_output = decoder(ae_encoder_output)

ae = Model(ae_input, ae_decoder_output, name="ae")
ae.summary()

"""Adding checkpoints before compiling to have the history of loss values during training"""

checkpoint_filepath = 'autoencoder_checkpoint.h5'
model_checkpoint = ModelCheckpoint(
    checkpoint_filepath,
    save_best_only=True,
    monitor='val_loss',  # You can change this to 'val_accuracy' if you have accuracy metrics
    mode='min',          # You can change this to 'max' if you have accuracy metrics
    verbose=1
)

history = History()

"""The training dynamically adjusts the training parameters during model training using the ReduceLROnPlateau callback, which reduces the learning rate when a monitored metric (e.g., validation loss) has stopped improving."""

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',  # You can change this to 'val_accuracy' if you have accuracy metrics
    factor=0.5,
    patience=3,
    min_lr=1e-6,
    verbose=1
)

"""Compile the model using `mse` loss function and `Adam` optimizer.
We could change the loss function to be `loss = tf.keras.metrics.categorical_accuracy()`.
See https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile for the compilation settings.
"""

ae.compile(loss="mse", optimizer=Adam(learning_rate=0.0001))

"""# Training the model :

Train the model with Checkpoint, History, and ReduceLROnPlateau callbacks
"""

training_history = ae.fit(
    x_train, x_train,
    epochs=nb_epochs,
    batch_size=batch_size,
    shuffle=True,
    validation_data=(x_test, x_test),
    callbacks=[model_checkpoint, history, reduce_lr]
)

"""Save the model weights

"""

ae.save_weights('autoencoder_weights.h5')

"""# Plot the training history

"""

plt.plot(training_history.history['loss'], label='Training Loss')
plt.plot(training_history.history['val_loss'], label='Validation Loss')
plt.title('Autoencoder Training History')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""Load the model weights

"""

ae.load_weights('autoencoder_weights.h5')

"""# Testing the model :

"""

encoded_images = encoder.predict(x_test)
decoded_images = decoder.predict(encoded_images)

"""# Display a grid of sampled digits :"""

# Visualize Original vs Reconstructed Images
n = 10  # Number of images to display
random_indices = np.random.choice(len(x_test), size=n, replace=False)
plt.figure(figsize=(20, 4))

for i, idx in enumerate(random_indices):
    # Original Images
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[idx].reshape(*input_shape))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.set_title('Original')

    # Reconstructed Images
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_images[idx].reshape(*input_shape))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.set_title('Reconstructed')

plt.show()

"""# Display how the latent space clusters different digit classes :

Naive plotting of only 2 dimensions of the N dimensional latent space :
"""

# Plotting the latent space with colors based on MNIST labels
plt.figure(figsize=(8, 6))
scatter = plt.scatter(encoded_images[:, 0], encoded_images[:, 1], c=y_test, cmap='viridis')
plt.colorbar(scatter, label='Digit Label')
plt.title('Latent Space with MNIST Labels')
plt.xlabel('Latent Variable 1')
plt.ylabel('Latent Variable 2')
plt.show()

"""# Display compression metrics :"""

x_test = x_test.reshape((len(x_test), 784, 1))
decoded_images = decoded_images.reshape((len(decoded_images), 784, 1))

"""## Bit Per Pixel (BPP):"""

bpp = (latent_dim * 32) / original_dim

"""## Signal-to-Noise Ratio (SNR):"""

snr = tf.image.psnr(x_test.reshape(-1, *input_shape), decoded_images.reshape(-1, *input_shape), max_val=1.0)
snr = np.mean(snr)

"""## Peak Signal-to-Noise Ratio (PSNR):"""

psnr = quality_metrics.psnr(x_test,decoded_images, max_p=255)

"""## Mean Square Error (MSE):"""

mse = np.mean((x_test - decoded_images)**2)

"""## Root Mean Square Error (RMSE):"""

rmse = quality_metrics.rmse(x_test,decoded_images, max_p=255)

"""## Peak Signal-to-Noise Ratio Human Vision (PSNR-HVS-M):"""

# Convert image shape to (28, 28) on all dataset
x_test_hvs = x_test.reshape((10000, 28, 28))
decoded_images_hvs = decoded_images.reshape((10000, 28, 28))

psnr_hvs_m = mean_psnr_hvs_m(x_test_hvs, decoded_images_hvs, 4)

"""## Structured Similarity Indexing Method (SSIM):"""

ssim = quality_metrics.ssim(x_test,decoded_images, max_p=255)

"""## Feature Similarity Indexing Method (FSIM):"""

fsim = quality_metrics.fsim(x_test,decoded_images)

# Create a list of tuples for the tabulate function
table_data = [
    ("BPP", bpp),
    ("SNR", snr),
    ("PSNR", psnr),
    ("MSE", mse),
    ("RMSE", rmse),
    ("PSNR_HVS_M", psnr_hvs_m),
    ("SSIM", ssim),
    ("FSIM", fsim),
]

# Print the table using tabulate
table = tabulate(table_data, headers=["Metric", "Value"], tablefmt="rst")
print(table)